{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d297f281",
   "metadata": {},
   "source": [
    "## Search Engine with Tools and Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "856f6dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## arxiv reseach paper\n",
    "## tool creation\n",
    "\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad40c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using the inbuilt tool of wikipedia\n",
    "\n",
    "api_wrapper_wiki=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be1b2fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating Arxiv Tool\n",
    "\n",
    "api_wrapper_arxiv=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "arxiv=ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504e8d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\ProgramData\\\\anaconda3\\\\envs\\\\clean-openai\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## combinning both\n",
    "\n",
    "tools=[wiki,arxiv]\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2557c711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B84B896010>, search_kwargs={})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Custom tools[RAG Tools]\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "# Fetch values\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "\n",
    "# Load the web page\n",
    "loader = WebBaseLoader(\"https://python.langchain.com/docs/integrations/providers/google/\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=500\n",
    ")\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# Build FAISS vector database\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectordb = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e6d16f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langchain-search'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating our tool from retriever\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever,\"langchain-search\",\"Search any information about langchain\")\n",
    "retriever_tool.name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fc28ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv,retriever_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40aadbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\ProgramData\\\\anaconda3\\\\envs\\\\clean-openai\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " Tool(name='langchain-search', description='Search any information about langchain', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001B85F14F100>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B84B896010>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001B85F14F4C0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B84B896010>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a239b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run all this tools with Agent and LLM Models\n",
    "\n",
    "## Tools, LLM --> AgentExecutor\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "# Fetch values\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e97a88ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001B85F29EC90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001B83D2FC810>, model_name='meta-llama/llama-4-maverick-17b-128e-instruct', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "# Instantiate ChatGroq LLM with your model\n",
    "llm = ChatGroq(\n",
    "    model=\"meta-llama/llama-4-maverick-17b-128e-instruct\",\n",
    "    api_key=groq_api_key\n",
    ")\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3297dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "  ## Create prompt template\n",
    "  \n",
    "from langchain.agents import initialize_agent, AgentType, load_tools\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "  \n",
    "# Create prompt (the INSTRUCTIONS)\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a research assistant with Wikipedia and arXiv access.\"),\n",
    "    HumanMessage(content=\"\"\"Question: {input}\n",
    "\n",
    "Tools: \n",
    "- wikipedia: Search Wikipedia for general information\n",
    "- arxiv: Search academic papers\n",
    "\n",
    "Response Format:\n",
    "Thought: your reasoning\n",
    "Action: tool name  \n",
    "Action Input: search query\n",
    "Observation: tool result\n",
    "Final Answer: comprehensive answer\n",
    "\n",
    "Begin:\"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93a7c7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Agent ready! Brain connected to hands with instructions!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_6628\\697481787.py:2: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Initialize agent (connect BRAIN to HANDS with INSTRUCTIONS)\n",
    "agent = initialize_agent(\n",
    "    tools=tools,          # HANDS\n",
    "    llm=llm,              # BRAIN ← This is the correct place!\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    prompt=agent_prompt,  # INSTRUCTIONS\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"✅ Agent ready! Brain connected to hands with instructions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e14fc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2074220c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_6628\\2887739939.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = agent.run(test_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer this question, I need to provide a general definition of artificial intelligence. I can use Wikipedia to get a reliable and concise definition.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      " \"action\": \"wikipedia\",\n",
      " \"action_input\": {\"query\": \"artificial intelligence\"}\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-makin\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: The Wikipedia summary provides a clear and concise definition of artificial intelligence. I can now use this information to formulate a final answer.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      " \"action\": \"Final Answer\",\n",
      " \"action_input\": \"Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "✅ SUCCESS! Agent is working!\n",
      "Result: Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making.\n"
     ]
    }
   ],
   "source": [
    "# Test with some research queries\n",
    "# Simple test to confirm it's working\n",
    "test_query = \"What is artificial intelligence?\"\n",
    "result = agent.run(test_query)\n",
    "print(\"✅ SUCCESS! Agent is working!\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40c1323b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCertainly! I'll provide a comprehensive overview of artificial intelligence, covering its basic definition and history, current state of the field, and latest advancements and research directions.\n",
      "\n",
      "Thought: First, I'll start by looking up the definition and history of artificial intelligence on Wikipedia.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      " \"action\": \"wikipedia\",\n",
      " \"action_input\": \"Artificial Intelligence\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-makin\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This will really test both tools\n",
    "advanced_query = \"\"\"\n",
    "Provide a comprehensive overview of artificial intelligence including:\n",
    "1. Basic definition and history from Wikipedia\n",
    "2. Current state of the field from recent arXiv papers\n",
    "3. Latest advancements and research directions\n",
    "\"\"\"\n",
    "\n",
    "result = agent.run(advanced_query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e2179c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To explain the attention mechanism in Large Language Models (LLMs) and find recent papers on the topic, I will first provide an overview of the attention mechanism. Then, I will search for recent papers on arxiv.org related to this topic.\n",
      "\n",
      "The attention mechanism is a key component of many LLMs, allowing them to focus on specific parts of the input when generating output. It was introduced to improve the performance of sequence-to-sequence models by enabling them to handle long-range dependencies more effectively.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      " \"action\": \"wikipedia\",\n",
      " \"action_input\": \"Attention Mechanism\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Attention (machine learning)\n",
      "Summary: In machine learning, attention is a method that determines the importance of each component in a sequence relative to the other components in that sequence. In natural language processing, importance is rep\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: The Wikipedia page on \"Attention (machine learning)\" provides a good overview of the attention mechanism. I'll summarize the key points related to LLMs and then search for recent papers on arxiv.org.\n",
      "\n",
      "The attention mechanism allows LLMs to weigh the importance of different input elements relative to each other, enabling the model to focus on the most relevant parts when generating output. This is particularly useful for handling long-range dependencies in sequences.\n",
      "\n",
      "Next, I'll search for recent papers on arxiv.org related to the attention mechanism in LLMs.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      " \"action\": \"arxiv\",\n",
      " \"action_input\": \"attention mechanism in large language models\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPublished: 2024-05-13\n",
      "Title: A Transformer with Stack Attention\n",
      "Authors: Jiaoda Li, Jennifer C. White, Mrinmaya Sachan, Ryan Cotterell\n",
      "Summary: Natural languages are believed to be (mildly) context-sensitive. Despite\n",
      "underpinning remarkably capable l\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I've found a recent paper on arxiv.org related to the attention mechanism in LLMs, titled \"A Transformer with Stack Attention\" published on 2024-05-13. I'll summarize the information and then provide a final answer.\n",
      "\n",
      "The attention mechanism is a crucial component of LLMs, enabling them to focus on specific parts of the input when generating output. It allows the model to weigh the importance of different input elements relative to each other, handling long-range dependencies in sequences effectively.\n",
      "\n",
      "Recent research, such as the paper \"A Transformer with Stack Attention,\" continues to explore and improve the attention mechanism in LLMs. This particular paper introduces a new transformer architecture with stack attention, potentially enhancing the capabilities of LLMs.\n",
      "\n",
      "Now, I'll provide a final answer summarizing the explanation of the attention mechanism and mentioning the recent paper found.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      " \"action\": \"Final Answer\",\n",
      " \"action_input\": \"The attention mechanism in Large Language Models (LLMs) is a method that allows the model to focus on specific parts of the input when generating output by weighing the importance of different input elements relative to each other. This is particularly useful for handling long-range dependencies in sequences. Recent research, such as the paper 'A Transformer with Stack Attention' published on 2024-05-13, continues to explore and improve the attention mechanism in LLMs, introducing new architectures like transformers with stack attention to potentially enhance LLM capabilities.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The attention mechanism in Large Language Models (LLMs) is a method that allows the model to focus on specific parts of the input when generating output by weighing the importance of different input elements relative to each other. This is particularly useful for handling long-range dependencies in sequences. Recent research, such as the paper 'A Transformer with Stack Attention' published on 2024-05-13, continues to explore and improve the attention mechanism in LLMs, introducing new architectures like transformers with stack attention to potentially enhance LLM capabilities.\n"
     ]
    }
   ],
   "source": [
    "# Run any research query\n",
    "query = \"Explain attention mechanism in LLMs and find recent papers\"\n",
    "result = agent.run(query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean-openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
